{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "from collections import namedtuple\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "from knowledge_graph import KnowledgeGraph\n",
    "from kg_env import BatchKGEnvironment\n",
    "from utils import *\n",
    "\n",
    "logger = None\n",
    "\n",
    "SavedAction = namedtuple('SavedAction', ['log_prob'])#, 'value'])\n",
    "\n",
    "# Hyper Parameters for DQN\n",
    "GAMMA = 0.9 # discount factor for target Q\n",
    "INITIAL_EPSILON = 0.5 # starting value of epsilon\n",
    "FINAL_EPSILON = 0.01 # final value of epsilon\n",
    "REPLAY_SIZE = 10000 # experience replay buffer size\n",
    "BATCH_SIZE = 32 # size of minibatch\n",
    "REPLACE_TARGET_FREQ = 10 # frequency to update target Q network\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN():\n",
    "    # DQN Agent\n",
    "    def __init__(self, env, state_dim, act_dim, gamma=0.99,hidden_sizes=[512,256]):\n",
    "    #def __init__(self, state_dim, act_dim, gamma=0.99, hidden_sizes=[512, 256]):\n",
    "        # init experience replay\n",
    "        self.replay_buffer = deque() #双向队列 可以从左append些什么\n",
    "        # init some parameters\n",
    "        self.time_step = 0\n",
    "        self.epsilon = INITIAL_EPSILON\n",
    "        self.state_dim = 400 #state_dim\n",
    "        #self.act_dim = act_dim\n",
    "        #env.observation_space.shape[0]\n",
    "        '''state_dim 要改!!!'''\n",
    "        self.action_dim = 32 #act_dim\n",
    "        #env.action_space.n\n",
    "        \n",
    "        self.saved_actions = []        \n",
    "        self.rewards = []\n",
    "        self.entropy = []\n",
    "        self.create_Q_network()\n",
    "        self.create_training_method()\n",
    "\n",
    "        # Init session\n",
    "        self.session = tf.InteractiveSession()\n",
    "        self.session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    \n",
    "    def create_Q_network(self):\n",
    "        #print('state_dim:',self.state_dim)\n",
    "        # input layer\n",
    "        #???\n",
    "        #self.state_input = tf.placeholder(\"float\", [self.state_dim,None])\n",
    "        self.state_input = tf.placeholder(\"float\", [None,None,self.state_dim])\n",
    "        print('state_input shape:',self.state_input.shape)\n",
    "        # network weights\n",
    "        with tf.variable_scope('current_net'):\n",
    "            W1 = self.weight_variable([self.state_dim,20])\n",
    "            b1 = self.bias_variable([20])\n",
    "            W2 = self.weight_variable([20,self.action_dim])\n",
    "            b2 = self.bias_variable([self.action_dim])\n",
    "\n",
    "            # hidden layers\n",
    "            \n",
    "            h_layer = tf.nn.relu(tf.matmul(self.state_input,W1) + b1)\n",
    "            # Q Value layer\n",
    "            #print('h_layer shape:',h_layer.shape)\n",
    "            #print('W2 shape:',W2.shape)\n",
    "            self.Q_value = tf.matmul(h_layer,W2) + b2\n",
    "            #print('Q_value shape:',self.Q_value.shape)\n",
    "\n",
    "        with tf.variable_scope('target_net'):\n",
    "            W1t = self.weight_variable([self.state_dim,20])\n",
    "            b1t = self.bias_variable([20])\n",
    "            W2t = self.weight_variable([20,self.action_dim])\n",
    "            b2t = self.bias_variable([self.action_dim])\n",
    "\n",
    "            # hidden layers\n",
    "            h_layer_t = tf.nn.relu(tf.matmul(self.state_input,W1t) + b1t)\n",
    "            # Q Value layer\n",
    "            self.target_Q_value = tf.matmul(h_layer_t,W2t) + b2t\n",
    "\n",
    "        t_params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='target_net')\n",
    "        e_params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='current_net')\n",
    "\n",
    "        with tf.variable_scope('soft_replacement'):\n",
    "            print('t_params:',t_params)\n",
    "            print('e_params:',e_params)\n",
    "            self.target_replace_op = [tf.assign(t, e) for t, e in zip(t_params, e_params)]\n",
    "    \n",
    "    def create_training_method(self):\n",
    "        self.action_input = tf.placeholder(\"float\",[None,self.action_dim]) # one hot presentation\n",
    "        #如果batch 是 32的话 这里的 none应该就要改成32\n",
    "        \n",
    "        self.y_input = tf.placeholder(\"float\",[None,32])\n",
    "        Q_action = tf.reduce_sum(tf.multiply(self.Q_value,self.action_input),reduction_indices = 1)\n",
    "        self.cost = tf.reduce_mean(tf.square(self.y_input - Q_action))\n",
    "        self.optimizer = tf.train.AdamOptimizer(0.0001).minimize(self.cost)\n",
    "        self.saver = tf.train.Saver()  # 1. 初始化saver\n",
    "        #optim.Adam(model.parameters(), lr=args.lr)\n",
    "            \n",
    "    def perceive(self,state,action,reward,next_state,done):\n",
    "        one_hot_action = np.zeros(self.action_dim)\n",
    "        #应该要 32*action_dim\n",
    "        one_hot_action[action] = 1\n",
    "        self.replay_buffer.append((state,one_hot_action,reward,next_state,done))\n",
    "        #np.concatenate([user_embed, node_embed, last_node_embed, last_relation_embed, older_node_embed,\n",
    "        #                           older_relation_embed])\n",
    "        #\n",
    "        #log_prob, value = self.saved_actions[i]\n",
    "        '''--------------------------!'''\n",
    "        #改成关系=1，=2，else吧\n",
    "        if len(self.replay_buffer) > REPLAY_SIZE:\n",
    "            self.replay_buffer.popleft()\n",
    "\n",
    "        if len(self.replay_buffer) > BATCH_SIZE:\n",
    "            self.train_Q_network()\n",
    "    \n",
    "    \n",
    "    def train_Q_network(self):\n",
    "        self.time_step += 1\n",
    "        # Step 1: obtain random minibatch from replay memory\n",
    "        minibatch = random.sample(self.replay_buffer,BATCH_SIZE)\n",
    "        state_batch = [data[0] for data in minibatch]\n",
    "        action_batch = [data[1] for data in minibatch]\n",
    "        reward_batch = [data[2] for data in minibatch]\n",
    "        next_state_batch = [data[3] for data in minibatch]\n",
    "\n",
    "        # Step 2: calculate y\n",
    "        y_batch = []\n",
    "        print('next_state_batch:',len(next_state_batch),len(next_state_batch[0]))\n",
    "        print(len(next_state_batch[0][0]))\n",
    "        current_Q_batch = self.Q_value.eval(feed_dict={self.state_input: next_state_batch})\n",
    "        print('current_Q_batch:',len(current_Q_batch),len(current_Q_batch[0]))\n",
    "        print(len(current_Q_batch[0][0]))\n",
    "        \n",
    "        #eval 把值算出来\n",
    "        max_action_next = np.argmax(current_Q_batch, axis=1)\n",
    "        \n",
    "        target_Q_batch = self.target_Q_value.eval(feed_dict={self.state_input: next_state_batch})\n",
    "        #print('target_Q_batch:',len(target_Q_batch),';',len(target_Q_batch[0]),';',target_Q_batch[0])\n",
    "        #a = np.append([c],[d],axis=0)\n",
    "        for i in range(0,BATCH_SIZE):\n",
    "            done = minibatch[i][4]\n",
    "            if i == 0:\n",
    "                if done:\n",
    "                    y_batch = np.array(reward_batch[i])\n",
    "                else:\n",
    "                    target_Q_value = target_Q_batch[i, i,max_action_next[i]]\n",
    "                    print(len(target_Q_batch),len(target_Q_batch[0]),len(target_Q_batch[0][0]))\n",
    "                    y_batch = np.array(reward_batch[i] + GAMMA * target_Q_value)\n",
    "            else:\n",
    "                if done:\n",
    "                    y_batch = np.append(y_batch,reward_batch[i])\n",
    "                else :\n",
    "                    target_Q_value = target_Q_batch[i, i,max_action_next[i]]\n",
    "                    y_batch = np.append(y_batch, reward_batch[i] + GAMMA * target_Q_value)\n",
    "        y_batch = y_batch.reshape(32,32)\n",
    "        \n",
    "        self.optimizer.run(feed_dict={self.y_input:y_batch,\n",
    "                                      self.action_input:action_batch,\n",
    "                                      self.state_input:state_batch})\n",
    "        \n",
    "        '''\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        del self.rewards[:]\n",
    "        del self.saved_actions[:]\n",
    "        del self.entropy[:]\n",
    "        '''\n",
    "        \n",
    "    def egreedy_action(self,batch_state,act_mask):#batch_state = state\n",
    "        \n",
    "        Q_value = self.Q_value.eval(feed_dict = {self.state_input:[batch_state]})[0] #[batch_state]\n",
    "        #这里的0是怎么的？\n",
    "        #Q_value_state = self.target_Q_value.eval(feed_dict = {self.state_input:[batch_state]})[0]\n",
    "        #print('Q_value_state:',Q_value_state)\n",
    "        Q_value = torch.tensor(Q_value)\n",
    "        ''''''\n",
    "        Q_value[1-act_mask] = -999999.0\n",
    "        Q_value = F.softmax(Q_value, dim=-1)\n",
    "        #print('egreedy_action-Qvalue_act_mask:')\n",
    "        #print(Q_value)\n",
    "        #print('len:',Q_value.shape)\n",
    "        \n",
    "        \n",
    "        m = Categorical(Q_value)#加起来应该不是1？说不准\n",
    "        #print('m:',m)\n",
    "        acts = m.sample()\n",
    "        #print('egreedy acts:',acts)\n",
    "        \n",
    "        # [CAVEAT] If sampled action is out of action_space, choose the first action in action_space.\n",
    "        '''\n",
    "        acts = torch.tensor(acts)\n",
    "        act_mask = torch.tensor(act_mask)\n",
    "        valid_idx = act_mask.gather(1, acts.view(-1, 1)).view(-1)#torch.gather(input=act_mask,dim=1,acts.view(-1,1))\n",
    "        #.view(-1行,1列)，-1 代表随便几行\n",
    "        acts = np.array(acts)\n",
    "        act_mask = np.array(act_mask)\n",
    "        valid_idx = np.array(valid_idx)\n",
    "        '''\n",
    "        #acts[valid_idx == 0] = 0\n",
    "        self.entropy.append(m.entropy())\n",
    "        \n",
    "        \n",
    "        if random.random() <= self.epsilon:\n",
    "            acts = []\n",
    "            self.epsilon -= (INITIAL_EPSILON - FINAL_EPSILON) / 10000\n",
    "            for i in range(BATCH_SIZE):\n",
    "                acts.append(random.randint(0,self.action_dim - 1))\n",
    "            #print('randomrandom_acts:')\n",
    "            #print(acts)\n",
    "            acts_log = torch.tensor(acts)\n",
    "            self.saved_actions.append(SavedAction(m.log_prob(acts_log)))#, value))\n",
    "            return acts #要return一行，不能只有一个值吧!!\n",
    "        else:\n",
    "            self.epsilon -= (INITIAL_EPSILON - FINAL_EPSILON) / 10000\n",
    "            #print('notrandom_acts')\n",
    "            #print(acts)\n",
    "            acts_log = torch.tensor(acts)\n",
    "            self.saved_actions.append(SavedAction(m.log_prob(acts_log)))#, value))\n",
    "            #!!!!\n",
    "            return acts #np.argmax(Q_value)\n",
    "        \n",
    "        '''\n",
    "        self.epsilon -= (INITIAL_EPSILON - FINAL_EPSILON) / 10000\n",
    "        print('notrandom_acts')\n",
    "        #print(acts)\n",
    "        return acts #np.argmax(Q_value)\n",
    "        '''\n",
    "        \n",
    "        \n",
    "    def action(self,batch_state,act_mask):\n",
    "        Q_value = self.Q_value.eval(feed_dict = {self.state_input:[batch_state]})[0]\n",
    "        Q_value = torch.tensor(Q_value)#!!!不一定对\n",
    "        \n",
    "        ''''''\n",
    "        #print('Q_value:',Q_value,';size:',len(Q_value),';',len(Q_value[0]))\n",
    "        Q_value[1-act_mask] = -999999.0\n",
    "        Q_value = F.softmax(Q_value, dim=-1)\n",
    "\n",
    "        m = Categorical(Q_value)#加起来应该不是1？说不准 \n",
    "        acts = m.sample()\n",
    "        # [CAVEAT] If sampled action is out of action_space, choose the first action in action_space.\n",
    "        '''\n",
    "        acts = torch.tensor(acts)\n",
    "        act_mask = torch.tensor(act_mask)\n",
    "        valid_idx = act_mask.gather(1, acts.view(-1, 1)).view(-1)#torch.gather(input=act_mask,dim=1,acts.view(-1,1))\n",
    "        acts = np.array(acts)\n",
    "        act_mask = np.array(act_mask)\n",
    "        valid_idx = np.array(valid_idx)\n",
    "        \n",
    "        #.view(-1行,1列)，-1 代表随便几行\n",
    "        acts[valid_idx == 0] = 0\n",
    "        '''\n",
    "        self.entropy.append(m.entropy())\n",
    "        acts_log = torch.tensor(acts)\n",
    "        self.saved_actions.append(SavedAction(m.log_prob(acts_log)))#, value))\n",
    "        #!!!!\n",
    "        return acts #np.argmax(Q_value)\n",
    "\n",
    "    def update_target_q_network(self, episode):\n",
    "        # update target Q netowrk\n",
    "        if episode % REPLACE_TARGET_FREQ == 0:\n",
    "            self.session.run(self.target_replace_op)\n",
    "            self.saver.save(self.session, 'ckp')  # 2. 保存模型和变量\n",
    "            #print('episode '+str(episode) +', target Q network params replaced!')\n",
    "            \n",
    "                \n",
    "        '''\n",
    "        self.saver = tf.train.Saver()  # 1. 初始化saver\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            saver.save(sess, 'ckp')  # 2. 保存模型和变量\n",
    "            !!!!!!!!!\n",
    "            #with tf.Session() as sess:\n",
    "                #saver = tf.import_meta_graph('ckp.meta')  # 3. 加载模型\n",
    "                #saver.restore(sess, 'ckp') \n",
    "        '''\n",
    "\n",
    "    def weight_variable(self,shape):\n",
    "        initial = tf.truncated_normal(shape)\n",
    "        return tf.Variable(initial)\n",
    "\n",
    "    def bias_variable(self,shape):\n",
    "        initial = tf.constant(0.01, shape = shape)\n",
    "        return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ACDataLoader(object):\n",
    "    def __init__(self, uids, batch_size):\n",
    "        self.uids = np.array(uids)\n",
    "        self.num_users = len(uids)\n",
    "        self.batch_size = batch_size\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self._rand_perm = np.random.permutation(self.num_users)\n",
    "        self._start_idx = 0\n",
    "        self._has_next = True\n",
    "\n",
    "    def has_next(self):\n",
    "        return self._has_next\n",
    "\n",
    "\n",
    "    #直接把训练集和测试机给改了就行了 序号都是 32的倍数就可\n",
    "    def get_batch(self):\n",
    "        if not self._has_next:\n",
    "            return None\n",
    "        # Multiple users per batch\n",
    "        end_idx = min(self._start_idx + self.batch_size, self.num_users)\n",
    "        #print('get_batch,end_idx:',end_idx,';',self.num_users)\n",
    "        batch_idx = self._rand_perm[self._start_idx:end_idx]\n",
    "        batch_uids = self.uids[batch_idx]\n",
    "        self._has_next = self._has_next and end_idx < self.num_users\n",
    "        self._start_idx = end_idx\n",
    "        \n",
    "        return batch_uids.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPISODE = 3000 # Episode limitation\n",
    "STEP = 300 # Step limitation in an episode\n",
    "TEST = 5 # The number of experiment test every 100 episode\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--dataset', type=str, default=BEAUTY, help='One of {clothing, cell, beauty, cd}')\n",
    "parser.add_argument('--name', type=str, default='train_agent', help='directory name.')\n",
    "parser.add_argument('--seed', type=int, default=123, help='random seed.')\n",
    "parser.add_argument('--gpu', type=str, default='0', help='gpu device.')\n",
    "parser.add_argument('--epochs', type=int, default=500, help='Max number of epochs.')\n",
    "parser.add_argument('--batch_size', type=int, default=32, help='batch size.')\n",
    "parser.add_argument('--lr', type=float, default=1e-4, help='learning rate.')\n",
    "parser.add_argument('--max_acts', type=int, default=250, help='Max number of actions.')\n",
    "#parser.add_argument('--state_dim', type=int, default=250, help='Max number of actions.')\n",
    "#\n",
    "parser.add_argument('--max_path_len', type=int, default=3, help='Max path length.')\n",
    "parser.add_argument('--gamma', type=float, default=0.99, help='reward discount factor.')\n",
    "parser.add_argument('--ent_weight', type=float, default=1e-3, help='weight factor for entropy loss')\n",
    "parser.add_argument('--act_dropout', type=float, default=0.5, help='action dropout rate.')\n",
    "parser.add_argument('--state_history', type=int, default=1, help='state history length')\n",
    "parser.add_argument('--hidden', type=int, nargs='*', default=[512, 256], help='number of samples')\n",
    "args = parser.parse_args(['--dataset',CELL])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]  Namespace(act_dropout=0.5, batch_size=32, dataset='cell', device='cpu', ent_weight=0.001, epochs=500, gamma=0.99, gpu='0', hidden=[512, 256], log_dir='./tmp/Amazon_Cellphones/train_agent', lr=0.0001, max_acts=250, max_path_len=3, name='train_agent', seed=123, state_history=1)\n"
     ]
    }
   ],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu\n",
    "args.device = torch.device('cuda:0') if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "args.log_dir = '{}/{}'.format(TMP_DIR[args.dataset], args.name)\n",
    "if not os.path.isdir(args.log_dir):\n",
    "    os.makedirs(args.log_dir)\n",
    "\n",
    "global logger\n",
    "logger = get_logger(args.log_dir + '/train_log_DQN.txt')\n",
    "logger.info(args)\n",
    "\n",
    "set_random_seed(args.seed)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args):\n",
    "    \n",
    "    # initialize OpenAI Gym env and dqn agent\n",
    "    #env = gym.make(ENV_NAME)\n",
    "    env = BatchKGEnvironment(args.dataset, args.max_acts, max_path_len=args.max_path_len, state_history=args.state_history)\n",
    "    uids = list(env.kg(USER).keys())\n",
    "    print('uids:',len(uids))\n",
    "    uids = np.arange(19488).tolist()\n",
    "    agent = DQN(env,env.state_dim,env.act_dim,gamma = args.gamma,hidden_sizes = args.hidden)\n",
    "    dataloader = ACDataLoader(uids, args.batch_size)\n",
    "    \n",
    "    #model = ActorCritic(env.state_dim, env.act_dim, gamma=args.gamma, hidden_sizes=args.hidden).to(args.device)\n",
    "    #logger.info('Parameters:' + str([i[0] for i in model.named_parameters()]))\n",
    "\n",
    "    '''    \n",
    "    uids = list(env.kg(USER).keys())\n",
    "    dataloader = ACDataLoader(uids, args.batch_size)\n",
    "    model = ActorCritic(env.state_dim, env.act_dim, gamma=args.gamma, hidden_sizes=args.hidden).to(args.device)\n",
    "    logger.info('Parameters:' + str([i[0] for i in model.named_parameters()]))\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr)    \n",
    "    '''\n",
    "    episode = 1\n",
    "    for epoch in range(0, args.epochs):\n",
    "        ### Start epoch ###\n",
    "        if epoch % 10 == 0:\n",
    "            print('epoch:',epoch)\n",
    "        dataloader.reset()\n",
    "        while dataloader.has_next():\n",
    "            batch_uids = dataloader.get_batch()\n",
    "            ### Start batch episodes ###\n",
    "            #print('batch_uids:',batch_uids,';',len(batch_uids))\n",
    "            batch_state1 = env.reset(batch_uids)  # numpy array of [bs, state_dim]\n",
    "            #print('egreedy_action, batch_state1:',batch_state1,';',len(batch_state1),';',len(batch_state1[0]))\n",
    "            for step in range(STEP):#while not done:\n",
    "\n",
    "                batch_act_mask = env.batch_action_mask(dropout=args.act_dropout)  # numpy array of size [bs, act_dim]\n",
    "                '''select action'''\n",
    "                #print('shape of batch state1:',batch_state1.shape)\n",
    "                batch_act_idx = agent.egreedy_action(batch_state1,batch_act_mask)#batch_act_mask\n",
    "                batch_state2, batch_reward, done = env.batch_step(batch_act_idx)\n",
    "                batch_state2 = batch_state2.reshape((-1,400))\n",
    "                agent.perceive(batch_state1,batch_act_idx,batch_reward,batch_state2,done)\n",
    "                agent.rewards.append(batch_reward)\n",
    "                #print('batch_state2:',batch_state2,';',len(batch_state2),';',len(batch_state2[0]))\n",
    "                batch_state1 = batch_state2\n",
    "                #train Q network\n",
    "                if done:\n",
    "                    break\n",
    "                # Test every 100 episodes\n",
    "            if epoch % 100 == 0:\n",
    "                total_reward = 0\n",
    "                for i in range(TEST):\n",
    "                    #batch_uids = dataloader.get_batch()\n",
    "                    #print('action batch_uids:',batch_uids)\n",
    "                    ### Start batch episodes ###\n",
    "                    batch_state1 = env.reset(batch_uids)  # numpy array of [bs, state_dim]\n",
    "                    #state = env.reset()\n",
    "                    for j in range(STEP):\n",
    "                        #env.render()#在屏幕上显示画面，不需要\n",
    "                        batch_act_mask = env.batch_action_mask(dropout=args.act_dropout)\n",
    "                        #print('before action, batch_state1:',batch_state1,';',len(batch_state1),';',len(batch_state1[0]))\n",
    "                        action = agent.action(batch_state1,batch_act_mask) # direct action for test\n",
    "                        batch_state2, batch_reward, done = env.batch_step(action)\n",
    "                        batch_state1 = batch_state2\n",
    "                        total_reward += batch_reward\n",
    "                        if done:\n",
    "                            break\n",
    "                ave_reward = total_reward/TEST\n",
    "                if episode % 100 == 0:\n",
    "                    #print ('episode: ',episode,'Evaluation Average Reward:',sum(ave_reward)/len(ave_reward))\n",
    "                    logger.info('episode: ',episode,'Evaluation Average Reward:',sum(ave_reward)/len(ave_reward))\n",
    "                episode = episode + 1 \n",
    "        agent.update_target_q_network(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load embedding: ./tmp/Amazon_Cellphones/transe_embed.pkl\n",
      "uids: 27879\n",
      "state_input shape: (?, ?, 400)\n",
      "t_params: [<tf.Variable 'target_net/Variable:0' shape=(400, 20) dtype=float32_ref>, <tf.Variable 'target_net/Variable_1:0' shape=(20,) dtype=float32_ref>, <tf.Variable 'target_net/Variable_2:0' shape=(20, 32) dtype=float32_ref>, <tf.Variable 'target_net/Variable_3:0' shape=(32,) dtype=float32_ref>]\n",
      "e_params: [<tf.Variable 'current_net/Variable:0' shape=(400, 20) dtype=float32_ref>, <tf.Variable 'current_net/Variable_1:0' shape=(20,) dtype=float32_ref>, <tf.Variable 'current_net/Variable_2:0' shape=(20, 32) dtype=float32_ref>, <tf.Variable 'current_net/Variable_3:0' shape=(32,) dtype=float32_ref>]\n",
      "epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:200: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\logging\\__init__.py\", line 1034, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\logging\\__init__.py\", line 880, in format\n",
      "    return fmt.format(record)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\logging\\__init__.py\", line 619, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\logging\\__init__.py\", line 380, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 563, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 528, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1764, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n",
      "    self.run()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 272, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 542, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2855, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3058, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3249, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-7-aad596905035>\", line 1, in <module>\n",
      "    train(args)\n",
      "  File \"<ipython-input-6-0b19d1d7a6a2>\", line 71, in train\n",
      "    logger.info('episode: ',episode,'Evaluation Average Reward:',sum(ave_reward)/len(ave_reward))\n",
      "Message: 'episode: '\n",
      "Arguments: (100, 'Evaluation Average Reward:', 0.04063469469547272)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\logging\\__init__.py\", line 1034, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\logging\\__init__.py\", line 880, in format\n",
      "    return fmt.format(record)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\logging\\__init__.py\", line 619, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\logging\\__init__.py\", line 380, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 563, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 528, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1764, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n",
      "    self.run()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 272, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 542, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2855, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3058, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3249, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-7-aad596905035>\", line 1, in <module>\n",
      "    train(args)\n",
      "  File \"<ipython-input-6-0b19d1d7a6a2>\", line 71, in train\n",
      "    logger.info('episode: ',episode,'Evaluation Average Reward:',sum(ave_reward)/len(ave_reward))\n",
      "Message: 'episode: '\n",
      "Arguments: (100, 'Evaluation Average Reward:', 0.04063469469547272)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "32 32 32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n",
      "next_state_batch: 32 32\n",
      "400\n",
      "current_Q_batch: 32 32\n",
      "32\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-aad596905035>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-0b19d1d7a6a2>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m     61\u001b[0m                         \u001b[1;31m#print('before action, batch_state1:',batch_state1,';',len(batch_state1),';',len(batch_state1[0]))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m                         \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_state1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_act_mask\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# direct action for test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                         \u001b[0mbatch_state2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_reward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m                         \u001b[0mbatch_state1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_state2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m                         \u001b[0mtotal_reward\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbatch_reward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\pgpr\\kg_env.py\u001b[0m in \u001b[0;36mbatch_step\u001b[1;34m(self, batch_act_idx)\u001b[0m\n\u001b[0;32m    247\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_done\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# must run before get actions, etc.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_curr_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_get_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_curr_actions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_get_actions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_done\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    250\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_curr_reward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_get_reward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\pgpr\\kg_env.py\u001b[0m in \u001b[0;36m_batch_get_actions\u001b[1;34m(self, batch_path, done)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_batch_get_actions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_actions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch_path\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\pgpr\\kg_env.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_batch_get_actions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_actions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch_path\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\pgpr\\kg_env.py\u001b[0m in \u001b[0;36m_get_actions\u001b[1;34m(self, path, done)\u001b[0m\n\u001b[0;32m    127\u001b[0m             \u001b[1;31m# if next_node_type == PRODUCT and next_node_id in self._target_pids:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m             \u001b[1;31m#    score = 99999.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m             \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m         \u001b[1;31m#print('embeds:',src_embed,'; size',len(src_embed))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[1;31m#print('scores:',score)#,'; size:',len(score))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load embedding: ./tmp/Amazon_Cellphones/transe_embed.pkl\n",
      "uids: 27879\n",
      "state_input shape: (?, ?, 400)\n",
      "t_params: [<tf.Variable 'target_net/Variable:0' shape=(400, 20) dtype=float32_ref>, <tf.Variable 'target_net/Variable_1:0' shape=(20,) dtype=float32_ref>, <tf.Variable 'target_net/Variable_2:0' shape=(20, 32) dtype=float32_ref>, <tf.Variable 'target_net/Variable_3:0' shape=(32,) dtype=float32_ref>]\n",
      "e_params: [<tf.Variable 'current_net/Variable:0' shape=(400, 20) dtype=float32_ref>, <tf.Variable 'current_net/Variable_1:0' shape=(20,) dtype=float32_ref>, <tf.Variable 'current_net/Variable_2:0' shape=(20, 32) dtype=float32_ref>, <tf.Variable 'current_net/Variable_3:0' shape=(32,) dtype=float32_ref>]\n",
      "epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:231: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:194: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode:  100 Evaluation Average Reward: 0.031032263276574667\n",
      "episode:  200 Evaluation Average Reward: 0.029486909729894255\n",
      "episode:  300 Evaluation Average Reward: 0.06116041322020465\n",
      "episode:  400 Evaluation Average Reward: 0.03670713166939095\n",
      "episode:  500 Evaluation Average Reward: 0.027048354771977756\n",
      "episode:  600 Evaluation Average Reward: 0.050040685496060174\n",
      "epoch: 10\n",
      "epoch: 20\n",
      "epoch: 30\n",
      "epoch: 40\n",
      "epoch: 50\n",
      "epoch: 60\n",
      "epoch: 70\n",
      "epoch: 80\n",
      "epoch: 90\n",
      "epoch: 100\n",
      "episode:  700 Evaluation Average Reward: 0.022291885349113725\n",
      "episode:  800 Evaluation Average Reward: 0.039250073107541535\n",
      "episode:  900 Evaluation Average Reward: 0.035041731603269\n",
      "episode:  1000 Evaluation Average Reward: 0.027887330121120612\n",
      "episode:  1100 Evaluation Average Reward: 0.04729438856011256\n",
      "episode:  1200 Evaluation Average Reward: 0.0332406351561076\n",
      "epoch: 110\n",
      "epoch: 120\n",
      "epoch: 130\n",
      "epoch: 140\n",
      "epoch: 150\n",
      "epoch: 160\n",
      "epoch: 170\n",
      "epoch: 180\n",
      "epoch: 190\n",
      "epoch: 200\n",
      "episode:  1300 Evaluation Average Reward: 0.02947752842082992\n",
      "episode:  1400 Evaluation Average Reward: 0.035905494486360115\n",
      "episode:  1500 Evaluation Average Reward: 0.037158830791850055\n",
      "episode:  1600 Evaluation Average Reward: 0.041731484699994326\n",
      "episode:  1700 Evaluation Average Reward: 0.020002166551057597\n",
      "episode:  1800 Evaluation Average Reward: 0.02787399940170872\n",
      "epoch: 210\n",
      "epoch: 220\n",
      "epoch: 230\n",
      "epoch: 240\n",
      "epoch: 250\n",
      "epoch: 260\n",
      "epoch: 270\n",
      "epoch: 280\n",
      "epoch: 290\n",
      "epoch: 300\n",
      "episode:  1900 Evaluation Average Reward: 0.02707789087289711\n",
      "episode:  2000 Evaluation Average Reward: 0.04421472983522109\n",
      "episode:  2100 Evaluation Average Reward: 0.0216622875930625\n",
      "episode:  2200 Evaluation Average Reward: 0.03169034671736881\n",
      "episode:  2300 Evaluation Average Reward: 0.035887195948453146\n",
      "episode:  2400 Evaluation Average Reward: 0.021310779354826084\n",
      "epoch: 310\n",
      "epoch: 320\n",
      "epoch: 330\n",
      "epoch: 340\n",
      "epoch: 350\n",
      "epoch: 360\n",
      "epoch: 370\n",
      "epoch: 380\n",
      "epoch: 390\n",
      "epoch: 400\n",
      "episode:  2500 Evaluation Average Reward: 0.027439506776863708\n",
      "episode:  2600 Evaluation Average Reward: 0.039818301950435855\n",
      "episode:  2700 Evaluation Average Reward: 0.04827424314862582\n",
      "episode:  2800 Evaluation Average Reward: 0.024940531089669087\n",
      "episode:  2900 Evaluation Average Reward: 0.03471145153162069\n",
      "episode:  3000 Evaluation Average Reward: 0.04836407109396531\n",
      "epoch: 410\n",
      "epoch: 420\n",
      "epoch: 430\n",
      "epoch: 440\n",
      "epoch: 450\n",
      "epoch: 460\n",
      "epoch: 470\n",
      "epoch: 480\n",
      "epoch: 490\n"
     ]
    }
   ],
   "source": [
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load embedding: ./tmp/Amazon_Cellphones/transe_embed.pkl\n",
      "uids: 27879\n",
      "state_input shape: (?, ?, 400)\n",
      "t_params: [<tf.Variable 'target_net/Variable:0' shape=(400, 20) dtype=float32_ref>, <tf.Variable 'target_net/Variable_1:0' shape=(20,) dtype=float32_ref>, <tf.Variable 'target_net/Variable_2:0' shape=(20, 32) dtype=float32_ref>, <tf.Variable 'target_net/Variable_3:0' shape=(32,) dtype=float32_ref>]\n",
      "e_params: [<tf.Variable 'current_net/Variable:0' shape=(400, 20) dtype=float32_ref>, <tf.Variable 'current_net/Variable_1:0' shape=(20,) dtype=float32_ref>, <tf.Variable 'current_net/Variable_2:0' shape=(20, 32) dtype=float32_ref>, <tf.Variable 'current_net/Variable_3:0' shape=(32,) dtype=float32_ref>]\n",
      "epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:233: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:196: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\logging\\__init__.py\", line 1034, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\logging\\__init__.py\", line 880, in format\n",
      "    return fmt.format(record)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\logging\\__init__.py\", line 619, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\logging\\__init__.py\", line 380, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 563, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 528, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1764, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n",
      "    self.run()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 272, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 542, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2855, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3058, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3249, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-7-aad596905035>\", line 1, in <module>\n",
      "    train(args)\n",
      "  File \"<ipython-input-6-0b19d1d7a6a2>\", line 71, in train\n",
      "    logger.info('episode: ',episode,'Evaluation Average Reward:',sum(ave_reward)/len(ave_reward))\n",
      "Message: 'episode: '\n",
      "Arguments: (100, 'Evaluation Average Reward:', 0.06257213549106383)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\logging\\__init__.py\", line 1034, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\logging\\__init__.py\", line 880, in format\n",
      "    return fmt.format(record)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\logging\\__init__.py\", line 619, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\logging\\__init__.py\", line 380, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 563, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 528, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1764, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n",
      "    self.run()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 272, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 542, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2855, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3058, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3249, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-7-aad596905035>\", line 1, in <module>\n",
      "    train(args)\n",
      "  File \"<ipython-input-6-0b19d1d7a6a2>\", line 71, in train\n",
      "    logger.info('episode: ',episode,'Evaluation Average Reward:',sum(ave_reward)/len(ave_reward))\n",
      "Message: 'episode: '\n",
      "Arguments: (100, 'Evaluation Average Reward:', 0.06257213549106383)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\logging\\__init__.py\", line 1034, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\logging\\__init__.py\", line 880, in format\n",
      "    return fmt.format(record)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\logging\\__init__.py\", line 619, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\logging\\__init__.py\", line 380, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 563, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 528, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1764, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n",
      "    self.run()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 272, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 542, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2855, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3058, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3249, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-7-aad596905035>\", line 1, in <module>\n",
      "    train(args)\n",
      "  File \"<ipython-input-6-0b19d1d7a6a2>\", line 71, in train\n",
      "    logger.info('episode: ',episode,'Evaluation Average Reward:',sum(ave_reward)/len(ave_reward))\n",
      "Message: 'episode: '\n",
      "Arguments: (200, 'Evaluation Average Reward:', 0.04947460037074052)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\logging\\__init__.py\", line 1034, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\logging\\__init__.py\", line 880, in format\n",
      "    return fmt.format(record)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\logging\\__init__.py\", line 619, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\logging\\__init__.py\", line 380, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 563, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 528, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1764, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n",
      "    self.run()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 272, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 542, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2855, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3058, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3249, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-7-aad596905035>\", line 1, in <module>\n",
      "    train(args)\n",
      "  File \"<ipython-input-6-0b19d1d7a6a2>\", line 71, in train\n",
      "    logger.info('episode: ',episode,'Evaluation Average Reward:',sum(ave_reward)/len(ave_reward))\n",
      "Message: 'episode: '\n",
      "Arguments: (200, 'Evaluation Average Reward:', 0.04947460037074052)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n",
      "32 32 32\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-aad596905035>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-0b19d1d7a6a2>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m     61\u001b[0m                         \u001b[1;31m#print('before action, batch_state1:',batch_state1,';',len(batch_state1),';',len(batch_state1[0]))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m                         \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_state1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_act_mask\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# direct action for test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                         \u001b[0mbatch_state2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_reward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m                         \u001b[0mbatch_state1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_state2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m                         \u001b[0mtotal_reward\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbatch_reward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\pgpr\\kg_env.py\u001b[0m in \u001b[0;36mbatch_step\u001b[1;34m(self, batch_act_idx)\u001b[0m\n\u001b[0;32m    247\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_done\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# must run before get actions, etc.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_curr_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_get_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_curr_actions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_get_actions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_done\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    250\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_curr_reward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_get_reward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\pgpr\\kg_env.py\u001b[0m in \u001b[0;36m_batch_get_actions\u001b[1;34m(self, batch_path, done)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_batch_get_actions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_actions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch_path\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\pgpr\\kg_env.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_batch_get_actions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_actions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch_path\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\pgpr\\kg_env.py\u001b[0m in \u001b[0;36m_get_actions\u001b[1;34m(self, path, done)\u001b[0m\n\u001b[0;32m    127\u001b[0m             \u001b[1;31m# if next_node_type == PRODUCT and next_node_id in self._target_pids:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m             \u001b[1;31m#    score = 99999.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m             \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m         \u001b[1;31m#print('embeds:',src_embed,'; size',len(src_embed))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[1;31m#print('scores:',score)#,'; size:',len(score))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-0d49d17824f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36mappend\u001b[1;34m(arr, values, axis)\u001b[0m\n\u001b[0;32m   4692\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4693\u001b[0m         \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4694\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4695\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input arrays must have same number of dimensions"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "c = np.array([[1,2],[5,6]])\n",
    "d = np.array([3,4])\n",
    "a = np.append(c,d,axis=0)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 2)\n",
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "(2, 3)\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Hyper Parameters\n",
    "#ENV_NAME = 'CartPole-v0'\n",
    "EPISODE = 3000 # Episode limitation\n",
    "STEP = 300 # Step limitation in an episode\n",
    "TEST = 5 # The number of experiment test every 100 episode\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--dataset', type=str, default=BEAUTY, help='One of {clothing, cell, beauty, cd}')\n",
    "    parser.add_argument('--name', type=str, default='train_agent', help='directory name.')\n",
    "    parser.add_argument('--seed', type=int, default=123, help='random seed.')\n",
    "    parser.add_argument('--gpu', type=str, default='0', help='gpu device.')\n",
    "    parser.add_argument('--epochs', type=int, default=50, help='Max number of epochs.')\n",
    "    parser.add_argument('--batch_size', type=int, default=32, help='batch size.')\n",
    "    parser.add_argument('--lr', type=float, default=1e-4, help='learning rate.')\n",
    "    parser.add_argument('--max_acts', type=int, default=250, help='Max number of actions.')\n",
    "    #\n",
    "    parser.add_argument('--max_path_len', type=int, default=3, help='Max path length.')\n",
    "    parser.add_argument('--gamma', type=float, default=0.99, help='reward discount factor.')\n",
    "    parser.add_argument('--ent_weight', type=float, default=1e-3, help='weight factor for entropy loss')\n",
    "    parser.add_argument('--act_dropout', type=float, default=0.5, help='action dropout rate.')\n",
    "    parser.add_argument('--state_history', type=int, default=1, help='state history length')\n",
    "    parser.add_argument('--hidden', type=int, nargs='*', default=[512, 256], help='number of samples')\n",
    "    args = parser.parse_args(['--dataset',CELL])\n",
    "    \n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu\n",
    "    args.device = torch.device('cuda:0') if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    args.log_dir = '{}/{}'.format(TMP_DIR[args.dataset], args.name)\n",
    "    if not os.path.isdir(args.log_dir):\n",
    "        os.makedirs(args.log_dir)\n",
    "\n",
    "    global logger\n",
    "    logger = get_logger(args.log_dir + '/train_log.txt')\n",
    "    logger.info(args)\n",
    "\n",
    "    set_random_seed(args.seed)\n",
    "    \n",
    "    \n",
    "    # initialize OpenAI Gym env and dqn agent\n",
    "    #env = gym.make(ENV_NAME)\n",
    "    env = BatchKGEnvironment(args.dataset, args.max_acts, max_path_len=args.max_path_len, state_history=args.state_history)\n",
    "    agent = DQN(env)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    uids = list(env.kg(USER).keys())\n",
    "    dataloader = ACDataLoader(uids, args.batch_size)\n",
    "    model = ActorCritic(env.state_dim, env.act_dim, gamma=args.gamma, hidden_sizes=args.hidden).to(args.device)\n",
    "    logger.info('Parameters:' + str([i[0] for i in model.named_parameters()]))\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "    \n",
    "    '''\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        ### Start epoch ###\n",
    "        dataloader.reset()\n",
    "        while dataloader.has_next():\n",
    "            batch_uids = dataloader.get_batch()\n",
    "            ### Start batch episodes ###\n",
    "            batch_state1 = env.reset(batch_uids)  # numpy array of [bs, state_dim]\n",
    "            #reset返回 current_state\n",
    "            #done = False\n",
    "            print('done:',done)\n",
    "            for step in range(STEP):#while not done:\n",
    "                #没有act mask？\n",
    "                batch_act_mask = env.batch_action_mask(dropout=args.act_dropout)  # numpy array of size [bs, act_dim]\n",
    "                '''select action'''\n",
    "                \n",
    "                batch_act_idx = agent.egreedy_action(batch_state1)#batch_act_mask\n",
    "                #model.select_action(batch_state, batch_act_mask, args.device)  # int\n",
    "                batch_state2, batch_reward, done = env.batch_step(batch_act_idx)\n",
    "                agent.perceive(batch_state1,batch_act_idx,batch_reward,batch_state2,done)\n",
    "                agent.rewards.append(batch_reward)\n",
    "                #train Q network\n",
    "                if done:\n",
    "                    break\n",
    "            # Test every 100 episodes\n",
    "        if epoch % 100 == 0:\n",
    "            total_reward = 0\n",
    "            for i in range(TEST):\n",
    "                batch_uids = dataloader.get_batch()\n",
    "                ### Start batch episodes ###\n",
    "                batch_state1 = env.reset(batch_uids)  # numpy array of [bs, state_dim]\n",
    "                #state = env.reset()\n",
    "                for j in range(STEP):\n",
    "                    #env.render()#在屏幕上显示画面，不需要\n",
    "                    action = agent.action(batch_state1) # direct action for test\n",
    "                    batch_state2, batch_reward, done = env.batch_step(action)\n",
    "                    total_reward += batch_reward\n",
    "                    if done:\n",
    "                        break\n",
    "            ave_reward = total_reward/TEST\n",
    "            print ('episode: ',episode,'Evaluation Average Reward:',ave_reward)\n",
    "        agent.update_target_q_network(epoch)\n",
    "        \n",
    "                \n",
    "            ### End of episodes ###\n",
    "\n",
    "            #lr = args.lr * max(1e-4, 1.0 - float(step) / (args.epochs * len(uids) / args.batch_size))\n",
    "            #for pg in optimizer.param_groups:\n",
    "                #pg['lr'] = lr\n",
    "\n",
    "'''    \n",
    "    for episode in range(EPISODE):\n",
    "        # initialize task\n",
    "        state = env.reset()\n",
    "        # Train\n",
    "        for step in range(STEP):\n",
    "            action = agent.egreedy_action(state) # e-greedy action for train\n",
    "            next_state,reward,done = env.batch_step(action)\n",
    "            # Define reward for agent\n",
    "            reward = -1 if done else 0.1\n",
    "            agent.perceive(state,action,reward,next_state,done)\n",
    "            #train_Q_network\n",
    "            state = next_state\n",
    "            if done:\n",
    "                break\n",
    "        # Test every 100 episodes\n",
    "        if episode % 100 == 0:\n",
    "            total_reward = 0\n",
    "            for i in range(TEST):\n",
    "                state = env.reset()\n",
    "                for j in range(STEP):\n",
    "                    env.render()\n",
    "                    action = agent.action(state) # direct action for test\n",
    "                    state,reward,done,_ = env.step(action)\n",
    "                    total_reward += reward\n",
    "                    if done:\n",
    "                        break\n",
    "            ave_reward = total_reward/TEST\n",
    "            print ('episode: ',episode,'Evaluation Average Reward:',ave_reward)\n",
    "        agent.update_target_q_network(episode)\n",
    "'''\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-f1c3257c14a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mknowledge_graph\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKnowledgeGraph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import random\n",
    "import torch\n",
    "from datetime import datetime\n",
    "\n",
    "from knowledge_graph import KnowledgeGraph\n",
    "from utils import *\n",
    "assert 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12800"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lol = []\n",
    "for j in range(32):\n",
    "    for i in range(400):\n",
    "        lol.append([i])\n",
    "\n",
    "l = sum(lol, [])\n",
    "len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1)\n",
      "tensor(1.3863)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.distributions import Categorical\n",
    "m = Categorical(torch.tensor([ 0.25, 0.25, 0.25, 0.25 ]))\n",
    "print(m.sample())\n",
    "print(m.entropy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args):\n",
    "    env = BatchKGEnvironment(args.dataset, args.max_acts, max_path_len=args.max_path_len, state_history=args.state_history)\n",
    "    uids = list(env.kg(USER).keys())\n",
    "    dataloader = ACDataLoader(uids, args.batch_size)\n",
    "    model = ActorCritic(env.state_dim, env.act_dim, gamma=args.gamma, hidden_sizes=args.hidden).to(args.device)\n",
    "    logger.info('Parameters:' + str([i[0] for i in model.named_parameters()]))\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "    total_losses, total_plosses, total_vlosses, total_entropy, total_rewards = [], [], [], [], []\n",
    "    step = 0\n",
    "    model.train()\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        ### Start epoch ###\n",
    "        dataloader.reset()\n",
    "        while dataloader.has_next():\n",
    "            batch_uids = dataloader.get_batch()\n",
    "            ### Start batch episodes ###\n",
    "            batch_state = env.reset(batch_uids)  # numpy array of [bs, state_dim]\n",
    "            done = False\n",
    "            while not done:\n",
    "                batch_act_mask = env.batch_action_mask(dropout=args.act_dropout)  # numpy array of size [bs, act_dim]\n",
    "                '''select action'''\n",
    "                batch_act_idx = model.select_action(batch_state, batch_act_mask, args.device)  # int\n",
    "                batch_state, batch_reward, done = env.batch_step(batch_act_idx)\n",
    "                model.rewards.append(batch_reward)\n",
    "            ### End of episodes ###\n",
    "\n",
    "            lr = args.lr * max(1e-4, 1.0 - float(step) / (args.epochs * len(uids) / args.batch_size))\n",
    "            for pg in optimizer.param_groups:\n",
    "                pg['lr'] = lr\n",
    "\n",
    "            # Update policy\n",
    "            total_rewards.append(np.sum(model.rewards))\n",
    "            loss, ploss, vloss, eloss = model.update(optimizer, args.device, args.ent_weight)\n",
    "            total_losses.append(loss)\n",
    "            total_plosses.append(ploss)\n",
    "            total_vlosses.append(vloss)\n",
    "            total_entropy.append(eloss)\n",
    "            step += 1\n",
    "\n",
    "            # Report performance\n",
    "            if step > 0 and step % 100 == 0:\n",
    "                avg_reward = np.mean(total_rewards) / args.batch_size\n",
    "                avg_loss = np.mean(total_losses)\n",
    "                avg_ploss = np.mean(total_plosses)\n",
    "                avg_vloss = np.mean(total_vlosses)\n",
    "                avg_entropy = np.mean(total_entropy)\n",
    "                total_losses, total_plosses, total_vlosses, total_entropy, total_rewards = [], [], [], [], []\n",
    "                logger.info(\n",
    "                        'epoch/step={:d}/{:d}'.format(epoch, step) +\n",
    "                        ' | loss={:.5f}'.format(avg_loss) +\n",
    "                        ' | ploss={:.5f}'.format(avg_ploss) +\n",
    "                        ' | vloss={:.5f}'.format(avg_vloss) +\n",
    "                        ' | entropy={:.5f}'.format(avg_entropy) +\n",
    "                        ' | reward={:.5f}'.format(avg_reward))\n",
    "        ### END of epoch ###\n",
    "\n",
    "        policy_file = '{}/policy_model_epoch_{}.ckpt'.format(args.log_dir, epoch)\n",
    "        logger.info(\"Save model to \" + policy_file)\n",
    "        torch.save(model.state_dict(), policy_file)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
