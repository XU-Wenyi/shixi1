{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import random\n",
    "import torch\n",
    "from datetime import datetime\n",
    "\n",
    "from knowledge_graph import KnowledgeGraph\n",
    "from utils import *\n",
    "\n",
    "\n",
    "class KGState(object):\n",
    "    def __init__(self, embed_size, history_len=1):\n",
    "        self.embed_size = embed_size\n",
    "        self.history_len = history_len  # mode: one of {full, current}\n",
    "        if history_len == 0:\n",
    "            self.dim = 2 * embed_size\n",
    "        elif history_len == 1:\n",
    "            self.dim = 4 * embed_size\n",
    "        elif history_len == 2:\n",
    "            self.dim = 6 * embed_size\n",
    "        else:\n",
    "            raise Exception('history length should be one of {0, 1, 2}')\n",
    "\n",
    "    def __call__(self, user_embed, node_embed, last_node_embed, last_relation_embed, older_node_embed,\n",
    "                 older_relation_embed):\n",
    "        if self.history_len == 0:\n",
    "            return np.concatenate([user_embed, node_embed])\n",
    "        elif self.history_len == 1:\n",
    "            return np.concatenate([user_embed, node_embed, last_node_embed, last_relation_embed])\n",
    "        elif self.history_len == 2:\n",
    "            return np.concatenate([user_embed, node_embed, last_node_embed, last_relation_embed, older_node_embed,\n",
    "                                   older_relation_embed])\n",
    "        else:\n",
    "            raise Exception('mode should be one of {full, current}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-9981d62ca1b7>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-9981d62ca1b7>\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    self.kg = load_kg(dataset_str)'''在utils里，load了pkl文件'''\u001b[0m\n\u001b[1;37m                                                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class BatchKGEnvironment(object):\n",
    "    def __init__(self, dataset_str, max_acts, max_path_len=3, state_history=1):\n",
    "        self.max_acts = max_acts\n",
    "        self.act_dim = max_acts + 1  # Add self-loop action, whose act_idx is always 0.\n",
    "        self.max_num_nodes = max_path_len + 1  # max number of hops (= #nodes - 1)\n",
    "        self.kg = load_kg(dataset_str)'''在utils里，load了pkl文件'''\n",
    "        \n",
    "        self.embeds = load_embed(dataset_str)\n",
    "        #print('self.embeds[0]',self.embeds[0])\n",
    "        self.embed_size = self.embeds[USER].shape[1]#dict,train_transe过来的\n",
    "        self.embeds[SELF_LOOP] = (np.zeros(self.embed_size), 0.0) #？？ self loop\n",
    "        \n",
    "        self.state_gen = KGState(self.embed_size, history_len=state_history)\n",
    "        self.state_dim = self.state_gen.dim\n",
    "\n",
    "        # Compute user-product scores for scaling.\n",
    "        u_p_scores = np.dot(self.embeds[USER] + self.embeds[PURCHASE][0], self.embeds[PRODUCT].T)\n",
    "        self.u_p_scales = np.max(u_p_scores, axis=1)\n",
    "\n",
    "        # Compute path patterns\n",
    "        self.patterns = []\n",
    "        for pattern_id in [1, 11, 12, 13, 14, 15, 16, 17, 18]:\n",
    "            pattern = PATH_PATTERN[pattern_id]\n",
    "            pattern = [SELF_LOOP] + [v[0] for v in pattern[1:]]  # pattern contains all relations\n",
    "            if pattern_id == 1:\n",
    "                pattern.append(SELF_LOOP)\n",
    "            self.patterns.append(tuple(pattern))\n",
    "        '''\n",
    "        # length = 3\n",
    "        1: ((None, USER), (MENTION, WORD), (DESCRIBED_AS, PRODUCT)),\n",
    "        # length = 4\n",
    "        11: ((None, USER), (PURCHASE, PRODUCT), (PURCHASE, USER), (PURCHASE, PRODUCT)),\n",
    "        12: ((None, USER), (PURCHASE, PRODUCT), (DESCRIBED_AS, WORD), (DESCRIBED_AS, PRODUCT)),\n",
    "        13: ((None, USER), (PURCHASE, PRODUCT), (PRODUCED_BY, BRAND), (PRODUCED_BY, PRODUCT)),\n",
    "        14: ((None, USER), (PURCHASE, PRODUCT), (BELONG_TO, CATEGORY), (BELONG_TO, PRODUCT)),\n",
    "        15: ((None, USER), (PURCHASE, PRODUCT), (ALSO_BOUGHT, RPRODUCT), (ALSO_BOUGHT, PRODUCT)),\n",
    "        16: ((None, USER), (PURCHASE, PRODUCT), (ALSO_VIEWED, RPRODUCT), (ALSO_VIEWED, PRODUCT)),\n",
    "        17: ((None, USER), (PURCHASE, PRODUCT), (BOUGHT_TOGETHER, RPRODUCT), (BOUGHT_TOGETHER, PRODUCT)),\n",
    "        18: ((None, USER), (MENTION, WORD), (MENTION, USER), (PURCHASE, PRODUCT)),\n",
    "        '''\n",
    "\n",
    "        # Following is current episode information.\n",
    "        self._batch_path = None  # list of tuples of (relation, node_type, node_id)\n",
    "        self._batch_curr_actions = None  # save current valid actions\n",
    "        self._batch_curr_state = None\n",
    "        self._batch_curr_reward = None\n",
    "        # Here only use 1 'done' indicator, since all paths have same length and will finish at the same time.\n",
    "        self._done = False\n",
    "\n",
    "    def _has_pattern(self, path):\n",
    "        pattern = tuple([v[0] for v in path])\n",
    "        return pattern in self.patterns\n",
    "\n",
    "    def _batch_has_pattern(self, batch_path):\n",
    "        return [self._has_pattern(path) for path in batch_path]\n",
    "\n",
    "    def _get_actions(self, path, done):\n",
    "        \"\"\"Compute actions for current node.\"\"\"\n",
    "        _, curr_node_type, curr_node_id = path[-1]\n",
    "        actions = [(SELF_LOOP, curr_node_id)]  # self-loop must be included.\n",
    "\n",
    "        # (1) If game is finished, only return self-loop action.\n",
    "        if done:\n",
    "            return actions\n",
    "\n",
    "        # (2) Get all possible edges from original knowledge graph.\n",
    "        # [CAVEAT] Must remove visited nodes!\n",
    "        relations_nodes = self.kg(curr_node_type, curr_node_id)'''self.kg = load_kg(dataset_str)'''\n",
    "        candidate_acts = []  # list of tuples of (relation, node_type, node_id)\n",
    "        visited_nodes = set([(v[1], v[2]) for v in path])\n",
    "        for r in relations_nodes:\n",
    "            next_node_type = KG_RELATION[curr_node_type][r]\n",
    "            next_node_ids = relations_nodes[r]\n",
    "            next_node_ids = [n for n in next_node_ids if (next_node_type, n) not in visited_nodes]  # filter\n",
    "            candidate_acts.extend(zip([r] * len(next_node_ids), next_node_ids))\n",
    "\n",
    "        # (3) If candidate action set is empty, only return self-loop action.\n",
    "        if len(candidate_acts) == 0:\n",
    "            return actions\n",
    "\n",
    "        # (4) If number of available actions is smaller than max_acts, return action sets.\n",
    "        if len(candidate_acts) <= self.max_acts:\n",
    "            candidate_acts = sorted(candidate_acts, key=lambda x: (x[0], x[1]))\n",
    "            actions.extend(candidate_acts)\n",
    "            return actions\n",
    "\n",
    "        # (5) If there are too many actions, do some deterministic trimming here!\n",
    "        user_embed = self.embeds[USER][path[0][-1]]\n",
    "        scores = []\n",
    "        for r, next_node_id in candidate_acts:\n",
    "            next_node_type = KG_RELATION[curr_node_type][r]#这个type里的序号\n",
    "            '''\n",
    "            KG_RELATION = {\n",
    "                USER: {PURCHASE: PRODUCT,MENTION: WORD,},\n",
    "                WORD: {MENTION: USER,DESCRIBED_AS: PRODUCT,},\n",
    "                PRODUCT: {PURCHASE: USER,DESCRIBED_AS: WORD,PRODUCED_BY: BRAND,BELONG_TO: CATEGORY,ALSO_BOUGHT: RPRODUCT,\n",
    "                    ALSO_VIEWED: RPRODUCT,BOUGHT_TOGETHER: RPRODUCT,},\n",
    "                BRAND: {PRODUCED_BY: PRODUCT,},\n",
    "                CATEGORY: {BELONG_TO: PRODUCT,},\n",
    "                RPRODUCT: {ALSO_BOUGHT: PRODUCT,ALSO_VIEWED: PRODUCT,BOUGHT_TOGETHER: PRODUCT,}\n",
    "            }\n",
    "            '''\n",
    "            if next_node_type == USER:\n",
    "                src_embed = user_embed\n",
    "            elif next_node_type == PRODUCT:\n",
    "                src_embed = user_embed + self.embeds[PURCHASE][0]\n",
    "            elif next_node_type == WORD:\n",
    "                src_embed = user_embed + self.embeds[MENTION][0]\n",
    "            else:  # BRAND, CATEGORY, RELATED_PRODUCT\n",
    "                src_embed = user_embed + self.embeds[PURCHASE][0] + self.embeds[r][0]\n",
    "            score = np.matmul(src_embed, self.embeds[next_node_type][next_node_id])\n",
    "            # This trimming may filter out target products!\n",
    "            # Manually set the score of target products a very large number.\n",
    "            # if next_node_type == PRODUCT and next_node_id in self._target_pids:\n",
    "            #    score = 99999.0\n",
    "            scores.append(score)\n",
    "        candidate_idxs = np.argsort(scores)[-self.max_acts:]  # choose actions with larger scores\n",
    "        candidate_acts = sorted([candidate_acts[i] for i in candidate_idxs], key=lambda x: (x[0], x[1]))\n",
    "        actions.extend(candidate_acts)\n",
    "        return actions\n",
    "\n",
    "    def _batch_get_actions(self, batch_path, done):\n",
    "        return [self._get_actions(path, done) for path in batch_path]\n",
    "\n",
    "    def _get_state(self, path):\n",
    "        \"\"\"Return state of numpy vector: [user_embed, curr_node_embed, last_node_embed, last_relation].\"\"\"\n",
    "        user_embed = self.embeds[USER][path[0][-1]]\n",
    "        zero_embed = np.zeros(self.embed_size)\n",
    "        if len(path) == 1:  # initial state\n",
    "            state = self.state_gen(user_embed, user_embed, zero_embed, zero_embed, zero_embed, zero_embed)\n",
    "            return state\n",
    "\n",
    "        older_relation, last_node_type, last_node_id = path[-2]\n",
    "        last_relation, curr_node_type, curr_node_id = path[-1]\n",
    "        curr_node_embed = self.embeds[curr_node_type][curr_node_id]\n",
    "        last_node_embed = self.embeds[last_node_type][last_node_id]\n",
    "        last_relation_embed, _ = self.embeds[last_relation]  # this can be self-loop!\n",
    "\n",
    "        if len(path) == 2:\n",
    "            state = self.state_gen(user_embed, curr_node_embed, last_node_embed, last_relation_embed, zero_embed,\n",
    "                                   zero_embed)\n",
    "            return state\n",
    "\n",
    "        _, older_node_type, older_node_id = path[-3]\n",
    "        older_node_embed = self.embeds[older_node_type][older_node_id]\n",
    "        older_relation_embed, _ = self.embeds[older_relation]\n",
    "        state = self.state_gen(user_embed, curr_node_embed, last_node_embed, last_relation_embed, older_node_embed,\n",
    "                               older_relation_embed)\n",
    "        return state\n",
    "\n",
    "    def _batch_get_state(self, batch_path):\n",
    "        batch_state = [self._get_state(path) for path in batch_path]\n",
    "        return np.vstack(batch_state)  # [bs, dim]\n",
    "\n",
    "    def _get_reward(self, path):\n",
    "        # If it is initial state or 1-hop search, reward is 0.\n",
    "        if len(path) <= 2:\n",
    "            return 0.0\n",
    "\n",
    "        if not self._has_pattern(path):\n",
    "            return 0.0\n",
    "\n",
    "        target_score = 0.0\n",
    "        _, curr_node_type, curr_node_id = path[-1]\n",
    "        if curr_node_type == PRODUCT:\n",
    "            # Give soft reward for other reached products.\n",
    "            uid = path[0][-1]\n",
    "            u_vec = self.embeds[USER][uid] + self.embeds[PURCHASE][0]\n",
    "            p_vec = self.embeds[PRODUCT][curr_node_id]\n",
    "            score = np.dot(u_vec, p_vec) / self.u_p_scales[uid]\n",
    "            '''???'''\n",
    "            target_score = max(score, 0.0)\n",
    "\n",
    "        return target_score\n",
    "\n",
    "    def _batch_get_reward(self, batch_path):\n",
    "        batch_reward = [self._get_reward(path) for path in batch_path]\n",
    "        return np.array(batch_reward)\n",
    "\n",
    "    def _is_done(self):\n",
    "        \"\"\"Episode ends only if max path length is reached.\"\"\"\n",
    "        return self._done or len(self._batch_path[0]) >= self.max_num_nodes\n",
    "\n",
    "    def reset(self, uids=None):\n",
    "        if uids is None:\n",
    "            all_uids = list(self.kg(USER).keys())\n",
    "            uids = [random.choice(all_uids)]\n",
    "\n",
    "        # each element is a tuple of (relation, entity_type, entity_id)\n",
    "        self._batch_path = [[(SELF_LOOP, USER, uid)] for uid in uids]\n",
    "        self._done = False\n",
    "        self._batch_curr_state = self._batch_get_state(self._batch_path)\n",
    "        self._batch_curr_actions = self._batch_get_actions(self._batch_path, self._done)\n",
    "        self._batch_curr_reward = self._batch_get_reward(self._batch_path)\n",
    "\n",
    "        return self._batch_curr_state\n",
    "\n",
    "    def batch_step(self, batch_act_idx):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            batch_act_idx: list of integers.\n",
    "        Returns:\n",
    "            batch_next_state: numpy array of size [bs, state_dim].\n",
    "            batch_reward: numpy array of size [bs].\n",
    "            done: True/False\n",
    "        \"\"\"\n",
    "        assert len(batch_act_idx) == len(self._batch_path)\n",
    "\n",
    "        # Execute batch actions.\n",
    "        for i in range(len(batch_act_idx)):\n",
    "            act_idx = batch_act_idx[i]\n",
    "            _, curr_node_type, curr_node_id = self._batch_path[i][-1]\n",
    "            relation, next_node_id = self._batch_curr_actions[i][act_idx]\n",
    "            if relation == SELF_LOOP:\n",
    "                next_node_type = curr_node_type\n",
    "            else:\n",
    "                next_node_type = KG_RELATION[curr_node_type][relation]\n",
    "            self._batch_path[i].append((relation, next_node_type, next_node_id))\n",
    "\n",
    "        self._done = self._is_done()  # must run before get actions, etc.\n",
    "        self._batch_curr_state = self._batch_get_state(self._batch_path)\n",
    "        self._batch_curr_actions = self._batch_get_actions(self._batch_path, self._done)\n",
    "        self._batch_curr_reward = self._batch_get_reward(self._batch_path)\n",
    "\n",
    "        return self._batch_curr_state, self._batch_curr_reward, self._done\n",
    "\n",
    "    def batch_action_mask(self, dropout=0.0):\n",
    "        \"\"\"Return action masks of size [bs, act_dim].\"\"\" #batch_state\n",
    "        batch_mask = []\n",
    "        for actions in self._batch_curr_actions:\n",
    "            act_idxs = list(range(len(actions)))\n",
    "            if dropout > 0 and len(act_idxs) >= 5:\n",
    "                keep_size = int(len(act_idxs[1:]) * (1.0 - dropout))\n",
    "                tmp = np.random.choice(act_idxs[1:], keep_size, replace=False).tolist()\n",
    "                act_idxs = [act_idxs[0]] + tmp\n",
    "            act_mask = np.zeros(self.act_dim, dtype=np.uint8)\n",
    "            act_mask[act_idxs] = 1\n",
    "            batch_mask.append(act_mask)\n",
    "        return np.vstack(batch_mask)\n",
    "\n",
    "    def print_path(self):\n",
    "        for path in self._batch_path:\n",
    "            msg = 'Path: {}({})'.format(path[0][1], path[0][2])\n",
    "            for node in path[1:]:\n",
    "                msg += ' =={}=> {}({})'.format(node[0], node[1], node[2])\n",
    "            print(msg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
